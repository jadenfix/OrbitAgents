# Prometheus configuration
prometheus:
  enabled: true
  
  prometheus:
    prometheusSpec:
      # Resource limits
      resources:
        requests:
          memory: 512Mi
          cpu: 200m
        limits:
          memory: 2Gi
          cpu: 1000m
      
      # Retention and storage
      retention: 30d
      retentionSize: 10GB
      
      # Storage class for persistence
      storageSpec:
        volumeClaimTemplate:
          spec:
            accessModes: ["ReadWriteOnce"]
            resources:
              requests:
                storage: 20Gi
      
      # Service discovery and scraping
      serviceMonitorSelectorNilUsesHelmValues: false
      podMonitorSelectorNilUsesHelmValues: false
      
      # Additional scrape configs for Orbit services
      additionalScrapeConfigs:
        - job_name: 'orbit-query-service'
          static_configs:
            - targets: ['query-service:8000']
          scrape_interval: 15s
          metrics_path: '/metrics'
          scrape_timeout: 10s
          
        - job_name: 'orbit-crawler-service'
          static_configs:
            - targets: ['crawler-service:8000']
          scrape_interval: 30s
          metrics_path: '/metrics'
          scrape_timeout: 10s
          
        - job_name: 'orbit-auth-service'
          static_configs:
            - targets: ['auth-service:8000']
          scrape_interval: 15s
          metrics_path: '/metrics'
          scrape_timeout: 10s

    # Alerting rules
    prometheusRule:
      enabled: true
      rules:
        - name: orbit.rules
          groups:
            - name: orbit-services
              rules:
                # 5xx error rate alert
                - alert: HighErrorRate
                  expr: (sum(rate(http_requests_total{status_code=~"5.."}[5m])) by (service) / sum(rate(http_requests_total[5m])) by (service)) * 100 > 1
                  for: 5m
                  labels:
                    severity: warning
                  annotations:
                    summary: "High 5xx error rate detected"
                    description: "Service {{ $labels.service }} has 5xx error rate above 1% for 5 minutes"
                
                # Crawl job failure alert  
                - alert: CrawlJobFailure
                  expr: increase(crawl_jobs_total{status="failed"}[1h]) > 0
                  for: 0m
                  labels:
                    severity: critical
                  annotations:
                    summary: "Crawl job failed"
                    description: "At least one crawl job has failed in the last hour"
                
                # High parse latency alert
                - alert: HighParseLatency
                  expr: histogram_quantile(0.95, sum(rate(query_parse_duration_seconds_bucket[5m])) by (le)) > 2.0
                  for: 5m
                  labels:
                    severity: warning
                  annotations:
                    summary: "High query parse latency"
                    description: "95th percentile parse latency is above 2 seconds"
                
                # Service down alert
                - alert: ServiceDown
                  expr: up == 0
                  for: 1m
                  labels:
                    severity: critical
                  annotations:
                    summary: "Service is down"
                    description: "Service {{ $labels.job }} is down"

# Grafana configuration
grafana:
  enabled: true
  
  # Admin credentials
  adminUser: admin
  adminPassword: orbit-grafana-2024
  
  # Resource limits
  resources:
    requests:
      memory: 256Mi
      cpu: 100m
    limits:
      memory: 512Mi
      cpu: 500m
  
  # Persistence
  persistence:
    enabled: true
    size: 5Gi
  
  # Service configuration
  service:
    type: LoadBalancer
    port: 3000
  
  # Grafana configuration
  grafana.ini:
    server:
      root_url: "http://localhost:3000"
    security:
      admin_user: admin
      admin_password: orbit-grafana-2024
    auth.anonymous:
      enabled: true
      org_role: Viewer
  
  # Data sources
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          type: prometheus
          url: http://prometheus-server:80
          access: proxy
          isDefault: true
          editable: true
  
  # Import dashboards
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: 'orbit-dashboards'
          orgId: 1
          folder: 'Orbit'
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/orbit
  
  dashboards:
    orbit:
      orbit-overview:
        gnetId: 15141  # Node Exporter Full
        datasource: Prometheus
      
      orbit-services:
        json: |
          {
            "dashboard": {
              "id": null,
              "title": "Orbit Services Dashboard",
              "tags": ["orbit", "microservices"],
              "timezone": "browser",
              "panels": [
                {
                  "id": 1,
                  "title": "API Request Rate",
                  "type": "graph",
                  "targets": [
                    {
                      "expr": "sum(rate(http_requests_total[5m])) by (service)",
                      "legendFormat": "{{service}}"
                    }
                  ],
                  "yAxes": [
                    {
                      "label": "Requests/sec"
                    }
                  ],
                  "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
                },
                {
                  "id": 2,
                  "title": "5xx Error Rate",
                  "type": "graph",
                  "targets": [
                    {
                      "expr": "(sum(rate(http_requests_total{status_code=~\"5..\"}[5m])) by (service) / sum(rate(http_requests_total[5m])) by (service)) * 100",
                      "legendFormat": "{{service}}"
                    }
                  ],
                  "yAxes": [
                    {
                      "label": "Error Rate %"
                    }
                  ],
                  "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
                },
                {
                  "id": 3,
                  "title": "Parse Latency (p95)",
                  "type": "graph",
                  "targets": [
                    {
                      "expr": "histogram_quantile(0.95, sum(rate(query_parse_duration_seconds_bucket[5m])) by (le))",
                      "legendFormat": "p95"
                    }
                  ],
                  "yAxes": [
                    {
                      "label": "Seconds"
                    }
                  ],
                  "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8}
                },
                {
                  "id": 4,
                  "title": "Crawl Lag",
                  "type": "graph",
                  "targets": [
                    {
                      "expr": "crawl_lag_seconds / 3600",
                      "legendFormat": "Hours since last crawl"
                    }
                  ],
                  "yAxes": [
                    {
                      "label": "Hours"
                    }
                  ],
                  "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8}
                }
              ],
              "time": {
                "from": "now-1h",
                "to": "now"
              },
              "refresh": "30s"
            }
          }

# Node Exporter (for system metrics)
nodeExporter:
  enabled: true

# Alertmanager configuration  
alertmanager:
  enabled: true
  
  alertmanagerSpec:
    resources:
      requests:
        memory: 128Mi
        cpu: 50m
      limits:
        memory: 256Mi
        cpu: 200m
  
  config:
    global:
      slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
    
    route:
      group_by: ['alertname']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'web.hook'
      routes:
        - match:
            severity: critical
          receiver: 'slack-critical'
        - match:
            severity: warning  
          receiver: 'slack-warnings'
    
    receivers:
      - name: 'web.hook'
        webhook_configs:
          - url: 'http://localhost:5001/'
      
      - name: 'slack-critical'
        slack_configs:
          - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
            channel: '#alerts-critical'
            title: 'Orbit Alert - Critical'
            text: 'Summary: {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
            
      - name: 'slack-warnings'  
        slack_configs:
          - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
            channel: '#alerts'
            title: 'Orbit Alert - Warning'
            text: 'Summary: {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}' 